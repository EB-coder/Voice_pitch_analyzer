import wave
import numpy as np
import matplotlib.pyplot as plt
from scipy.fft import fft
from scipy.signal import find_peaks

# ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ¾ĞºĞ½Ğ°
WINDOW_SIZE = 2048
HOP_SIZE = 512

# ĞÑ‚ĞºÑ€Ñ‹Ñ‚Ğ¸Ğµ WAV Ñ„Ğ°Ğ¹Ğ»Ğ°
filename = "voice.wav"
wf = wave.open(filename, 'rb')
n_channels = wf.getnchannels()
sampwidth = wf.getsampwidth()
framerate = wf.getframerate()
n_frames = wf.getnframes()

# Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
raw_data = wf.readframes(n_frames)
wf.close()

# ĞŸÑ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ² Ğ¼Ğ°ÑÑĞ¸Ğ²
audio = np.frombuffer(raw_data, dtype=np.int16)
audio = audio / np.max(np.abs(audio))  # Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ

# ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ¾ĞºĞ¾Ğ½
pitches = []
times = []

for i in range(0, len(audio) - WINDOW_SIZE, HOP_SIZE):
    window = audio[i:i+WINDOW_SIZE]
    fft_spectrum = np.abs(fft(window))[:WINDOW_SIZE // 2]
    freqs = np.fft.fftfreq(WINDOW_SIZE, d=1.0 / framerate)[:WINDOW_SIZE // 2]

    # ĞŸĞ¾Ğ¸ÑĞº Ğ¿Ğ¸ĞºĞ¾Ğ²
    peak_indices, _ = find_peaks(fft_spectrum, height=0.1)
    if len(peak_indices) > 0:
        dominant_freq = freqs[peak_indices[0]]
    else:
        dominant_freq = 0

    pitches.append(dominant_freq)
    times.append(i / framerate)

# Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ½ÑƒĞ»ĞµĞ¹
cleaned_pitches = [p for p in pitches if p > 50 and p < 1000]

# Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°
mean_pitch = np.mean(cleaned_pitches)
max_pitch = np.max(cleaned_pitches)
min_pitch = np.min(cleaned_pitches)
std_pitch = np.std(cleaned_pitches)

# Ğ’Ñ‹Ğ²Ğ¾Ğ´
print(f"ğŸ“ˆ Ğ¡Ñ€ĞµĞ´Ğ½ÑÑ Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ğ° (pitch): {mean_pitch:.2f} Ğ“Ñ†")
print(f"ğŸ”¼ ĞœĞ°ĞºÑĞ¸Ğ¼ÑƒĞ¼: {max_pitch:.2f} Ğ“Ñ†")
print(f"ğŸ”½ ĞœĞ¸Ğ½Ğ¸Ğ¼ÑƒĞ¼: {min_pitch:.2f} Ğ“Ñ†")
print(f"Â± Ğ¡Ñ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ğ¾Ğµ Ğ¾Ñ‚ĞºĞ»Ğ¾Ğ½ĞµĞ½Ğ¸Ğµ: {std_pitch:.2f} Ğ“Ñ†")

# ĞŸĞ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ğµ Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ°
plt.figure(figsize=(10, 4))
plt.plot(times, pitches, color='purple', label='Pitch (Hz)')
plt.xlabel("Ğ’Ñ€ĞµĞ¼Ñ (ÑĞµĞº)")
plt.ylabel("Ğ§Ğ°ÑÑ‚Ğ¾Ñ‚Ğ° (Ğ“Ñ†)")
plt.title("ĞĞ½Ğ°Ğ»Ğ¸Ğ· pitch Ğ³Ğ¾Ğ»Ğ¾ÑĞ°")
plt.grid(True)
plt.legend()
plt.tight_layout()
plt.show()


# python analyze_pitch.py